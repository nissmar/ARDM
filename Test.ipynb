{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fe875c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.distributions import Categorical, OneHotCategorical\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def find_most_similar(seq,L):\n",
    "    ratios = np.array([similar(seq,e) for e in L])\n",
    "    return L[ratios.argmax()]\n",
    "\n",
    "\n",
    "# a set of six word phrases\n",
    "phrases = [\n",
    "    'the cat sat on the mat ',\n",
    "    'the quick brown fox jumped over ',\n",
    "    'four legs good two legs bad '\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2ad38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cure_text(filename):\n",
    "    file = open(filename, 'rt')\n",
    "    text = file.read()\n",
    "    text = text.replace(\"...\", \".\")\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    text = text.replace(\"\\\"\", \" \")\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e503f0f",
   "metadata": {},
   "source": [
    "# Candidats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d889cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "text = cure_text('candidats.txt') + cure_text('lepetitprince.txt')\n",
    "words = text.split()\n",
    "words = [''.join(filter(str.isalnum, w)).lower() for w in words]\n",
    "words = [e for e in words if len(e)>0 and not(e.isdigit())]\n",
    "k=6\n",
    "phrases = [\" \".join(words[i:i+k])+' ' for i in range(0,len(words)-k, k)]\n",
    "phrases = phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255f4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = list(text.lower())\n",
    "k=16\n",
    "phrases = [''.join(characters[i:i+k]) for i in range(0,len(characters)-k, k//4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a7463",
   "metadata": {},
   "source": [
    "# Le petit prince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a573ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "text = cure_text('lepetitprince.txt')\n",
    "\n",
    "words = text.split()\n",
    "words = [''.join(filter(str.isalnum, w)).lower() for w in words]\n",
    "words = [e for e in words if len(e)>0 and not(e.isdigit())]\n",
    "k=6\n",
    "phrases = [\" \".join(words[i:i+k])+' ' for i in range(0,len(words)-k, k)]\n",
    "phrases = phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3afc075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lorsque',\n",
       " 'javais',\n",
       " 'six',\n",
       " 'ans',\n",
       " 'jai',\n",
       " 'vu',\n",
       " 'une',\n",
       " 'fois',\n",
       " 'une',\n",
       " 'magnifique',\n",
       " 'image',\n",
       " 'dans',\n",
       " 'un',\n",
       " 'livre',\n",
       " 'sur',\n",
       " 'la',\n",
       " 'forêt',\n",
       " 'vierge',\n",
       " 'qui',\n",
       " 'sappelait',\n",
       " 'histoires',\n",
       " 'vécues',\n",
       " 'ça',\n",
       " 'représentait',\n",
       " 'un',\n",
       " 'serpent',\n",
       " 'boa',\n",
       " 'qui',\n",
       " 'avalait',\n",
       " 'un',\n",
       " 'fauve',\n",
       " 'voilà',\n",
       " 'la',\n",
       " 'copie',\n",
       " 'du',\n",
       " 'dessin',\n",
       " 'on',\n",
       " 'disait',\n",
       " 'dans',\n",
       " 'le',\n",
       " 'livre',\n",
       " 'les',\n",
       " 'serpents',\n",
       " 'boas',\n",
       " 'avalent',\n",
       " 'leur',\n",
       " 'proie',\n",
       " 'tout',\n",
       " 'entière',\n",
       " 'sans',\n",
       " 'la',\n",
       " 'mâcher',\n",
       " 'ensuite',\n",
       " 'ils',\n",
       " 'ne',\n",
       " 'peuvent',\n",
       " 'plus',\n",
       " 'bouger',\n",
       " 'et',\n",
       " 'ils',\n",
       " 'dorment',\n",
       " 'pendant',\n",
       " 'les',\n",
       " 'six',\n",
       " 'mois',\n",
       " 'de',\n",
       " 'leur',\n",
       " 'digestion',\n",
       " 'jai',\n",
       " 'alors',\n",
       " 'beaucoup',\n",
       " 'réfléchi',\n",
       " 'sur',\n",
       " 'les',\n",
       " 'aventures',\n",
       " 'de',\n",
       " 'la',\n",
       " 'jungle',\n",
       " 'et',\n",
       " 'à',\n",
       " 'mon',\n",
       " 'tour',\n",
       " 'jai',\n",
       " 'réussi',\n",
       " 'avec',\n",
       " 'un',\n",
       " 'crayon',\n",
       " 'de',\n",
       " 'couleur',\n",
       " 'à',\n",
       " 'tracer',\n",
       " 'mon',\n",
       " 'premier',\n",
       " 'dessin',\n",
       " 'mon',\n",
       " 'dessin',\n",
       " 'numéro',\n",
       " 'i',\n",
       " 'il',\n",
       " 'était',\n",
       " 'comme',\n",
       " 'ça',\n",
       " 'jai',\n",
       " 'montré',\n",
       " 'mon',\n",
       " 'chef',\n",
       " 'doeuvre',\n",
       " 'aux',\n",
       " 'grandes',\n",
       " 'personnes',\n",
       " 'et',\n",
       " 'je',\n",
       " 'leur',\n",
       " 'ai',\n",
       " 'demandé',\n",
       " 'si',\n",
       " 'mon',\n",
       " 'dessin',\n",
       " 'leur',\n",
       " 'faisait',\n",
       " 'peur',\n",
       " 'elles',\n",
       " 'mont',\n",
       " 'répondu',\n",
       " 'pourquoi',\n",
       " 'un',\n",
       " 'chapeau',\n",
       " 'ferait',\n",
       " 'il',\n",
       " 'peur',\n",
       " 'mon',\n",
       " 'dessin',\n",
       " 'ne',\n",
       " 'représentait',\n",
       " 'pas',\n",
       " 'un',\n",
       " 'chapeau',\n",
       " 'il',\n",
       " 'représentait',\n",
       " 'un',\n",
       " 'serpent',\n",
       " 'boa',\n",
       " 'qui',\n",
       " 'digérait',\n",
       " 'un',\n",
       " 'éléphant',\n",
       " 'jai',\n",
       " 'alors',\n",
       " 'dessiné',\n",
       " 'lintérieur',\n",
       " 'du',\n",
       " 'serpent',\n",
       " 'boa',\n",
       " 'afin',\n",
       " 'que',\n",
       " 'les',\n",
       " 'grandes',\n",
       " 'personnes',\n",
       " 'puissent',\n",
       " 'comprendre',\n",
       " 'elles',\n",
       " 'ont',\n",
       " 'toujours',\n",
       " 'besoin',\n",
       " 'dexplications',\n",
       " 'mon',\n",
       " 'dessin',\n",
       " 'numéro',\n",
       " 'était',\n",
       " 'comme',\n",
       " 'ça',\n",
       " 'les',\n",
       " 'grandes',\n",
       " 'personnes',\n",
       " 'mont',\n",
       " 'conseillé',\n",
       " 'de',\n",
       " 'laisser',\n",
       " 'de',\n",
       " 'côté',\n",
       " 'les',\n",
       " 'dessins',\n",
       " 'de',\n",
       " 'serpents',\n",
       " 'boas',\n",
       " 'ouverts',\n",
       " 'ou',\n",
       " 'fermés',\n",
       " 'et',\n",
       " 'de',\n",
       " 'mintéresser',\n",
       " 'plutôt',\n",
       " 'à',\n",
       " 'la',\n",
       " 'géographie',\n",
       " 'à',\n",
       " 'lhistoire',\n",
       " 'au',\n",
       " 'calcul',\n",
       " 'et',\n",
       " 'à',\n",
       " 'la',\n",
       " 'grammaire',\n",
       " 'cest',\n",
       " 'ainsi',\n",
       " 'que',\n",
       " 'jai',\n",
       " 'abandonné',\n",
       " 'à',\n",
       " 'lâge',\n",
       " 'de',\n",
       " 'six',\n",
       " 'ans',\n",
       " 'une',\n",
       " 'magnifique',\n",
       " 'carrière',\n",
       " 'de',\n",
       " 'peintre',\n",
       " 'javais',\n",
       " 'été',\n",
       " 'découragé',\n",
       " 'par',\n",
       " 'linsuccès',\n",
       " 'de',\n",
       " 'mon',\n",
       " 'dessin',\n",
       " 'numéro',\n",
       " 'i',\n",
       " 'et',\n",
       " 'de',\n",
       " 'mon',\n",
       " 'dessin',\n",
       " 'numéro',\n",
       " 'les',\n",
       " 'grandes',\n",
       " 'personnes',\n",
       " 'ne',\n",
       " 'comprennent',\n",
       " 'jamais',\n",
       " 'rien',\n",
       " 'toutes',\n",
       " 'seules',\n",
       " 'et',\n",
       " 'cest',\n",
       " 'fatigant',\n",
       " 'pour',\n",
       " 'les',\n",
       " 'enfants',\n",
       " 'de',\n",
       " 'toujours',\n",
       " 'et',\n",
       " 'toujours',\n",
       " 'leur',\n",
       " 'donner',\n",
       " 'des',\n",
       " 'explications',\n",
       " 'jai',\n",
       " 'donc',\n",
       " 'dû',\n",
       " 'choisir',\n",
       " 'un',\n",
       " 'autre',\n",
       " 'métier',\n",
       " 'et',\n",
       " 'jai',\n",
       " 'appris',\n",
       " 'à',\n",
       " 'piloter',\n",
       " 'des',\n",
       " 'avions',\n",
       " 'jai',\n",
       " 'volé',\n",
       " 'un',\n",
       " 'peu',\n",
       " 'partout',\n",
       " 'dans',\n",
       " 'le',\n",
       " 'monde',\n",
       " 'et',\n",
       " 'la',\n",
       " 'géographie',\n",
       " 'cest',\n",
       " 'exact',\n",
       " 'ma',\n",
       " 'beaucoup',\n",
       " 'servi',\n",
       " 'je',\n",
       " 'savais',\n",
       " 'reconnaître',\n",
       " 'du',\n",
       " 'premier',\n",
       " 'coup',\n",
       " 'doeil',\n",
       " 'la',\n",
       " 'chine',\n",
       " 'de',\n",
       " 'larizona',\n",
       " 'cest',\n",
       " 'très',\n",
       " 'utile',\n",
       " 'si',\n",
       " 'lon',\n",
       " 'est',\n",
       " 'égaré',\n",
       " 'pendant',\n",
       " 'la',\n",
       " 'nuit',\n",
       " 'jai',\n",
       " 'ainsi',\n",
       " 'eu',\n",
       " 'au',\n",
       " 'cours',\n",
       " 'de',\n",
       " 'ma',\n",
       " 'vie',\n",
       " 'des',\n",
       " 'tas',\n",
       " 'de',\n",
       " 'contacts',\n",
       " 'avec',\n",
       " 'des',\n",
       " 'tas',\n",
       " 'de',\n",
       " 'gens',\n",
       " 'sérieux',\n",
       " 'jai',\n",
       " 'beaucoup',\n",
       " 'vécu',\n",
       " 'chez',\n",
       " 'les',\n",
       " 'grandes',\n",
       " 'personnes',\n",
       " 'je',\n",
       " 'les',\n",
       " 'ai',\n",
       " 'vues',\n",
       " 'de',\n",
       " 'très',\n",
       " 'près',\n",
       " 'ça',\n",
       " 'na',\n",
       " 'pas',\n",
       " 'trop',\n",
       " 'amélioré',\n",
       " 'mon',\n",
       " 'opinion',\n",
       " 'quand',\n",
       " 'jen',\n",
       " 'rencontrais',\n",
       " 'une',\n",
       " 'qui',\n",
       " 'me',\n",
       " 'paraissait',\n",
       " 'un',\n",
       " 'peu',\n",
       " 'lucide',\n",
       " 'je',\n",
       " 'faisais',\n",
       " 'lexpérience',\n",
       " 'sur',\n",
       " 'elle',\n",
       " 'de',\n",
       " 'mon',\n",
       " 'dessin',\n",
       " 'numéro',\n",
       " 'i',\n",
       " 'que',\n",
       " 'jai',\n",
       " 'toujours',\n",
       " 'conservé',\n",
       " 'je',\n",
       " 'voulais',\n",
       " 'savoir',\n",
       " 'si',\n",
       " 'elle',\n",
       " 'était',\n",
       " 'vraiment',\n",
       " 'compréhensive',\n",
       " 'mais',\n",
       " 'toujours',\n",
       " 'elle',\n",
       " 'me',\n",
       " 'répondait',\n",
       " 'cest',\n",
       " 'un',\n",
       " 'chapeau',\n",
       " 'alors',\n",
       " 'je',\n",
       " 'ne',\n",
       " 'lui',\n",
       " 'parlais',\n",
       " 'ni',\n",
       " 'de',\n",
       " 'serpents',\n",
       " 'boas',\n",
       " 'ni',\n",
       " 'de',\n",
       " 'forêts',\n",
       " 'vierges',\n",
       " 'ni',\n",
       " 'détoiles',\n",
       " 'je',\n",
       " 'me',\n",
       " 'mettais',\n",
       " 'à',\n",
       " 'sa',\n",
       " 'portée',\n",
       " 'je',\n",
       " 'lui',\n",
       " 'parlais',\n",
       " 'de',\n",
       " 'bridge',\n",
       " 'de',\n",
       " 'golf',\n",
       " 'de',\n",
       " 'politique',\n",
       " 'et',\n",
       " 'de',\n",
       " 'cravates',\n",
       " 'et',\n",
       " 'la',\n",
       " 'grande',\n",
       " 'personne',\n",
       " 'était',\n",
       " 'bien',\n",
       " 'contente',\n",
       " 'de',\n",
       " 'connaître',\n",
       " 'un',\n",
       " 'homme',\n",
       " 'aussi',\n",
       " 'raisonnable',\n",
       " 'jai',\n",
       " 'ainsi',\n",
       " 'vécu',\n",
       " 'seul',\n",
       " 'sans',\n",
       " 'personne',\n",
       " 'avec',\n",
       " 'qui',\n",
       " 'parler',\n",
       " 'véritablement',\n",
       " 'jusquà',\n",
       " 'une',\n",
       " 'panne',\n",
       " 'dans',\n",
       " 'le',\n",
       " 'désert',\n",
       " 'du',\n",
       " 'sahara',\n",
       " 'il',\n",
       " 'y',\n",
       " 'a',\n",
       " 'six',\n",
       " 'ans',\n",
       " 'quelque',\n",
       " 'chose',\n",
       " 'sétait',\n",
       " 'cassée',\n",
       " 'dans',\n",
       " 'mon',\n",
       " 'moteur',\n",
       " 'et',\n",
       " 'comme',\n",
       " 'je',\n",
       " 'navais',\n",
       " 'avec',\n",
       " 'moi',\n",
       " 'ni',\n",
       " 'mécanicien',\n",
       " 'ni',\n",
       " 'passagers',\n",
       " 'je',\n",
       " 'me',\n",
       " 'préparai',\n",
       " 'à',\n",
       " 'essayer',\n",
       " 'de',\n",
       " 'réussir',\n",
       " 'tout',\n",
       " 'seul',\n",
       " 'une',\n",
       " 'réparation',\n",
       " 'difficile',\n",
       " 'cétait',\n",
       " 'pour',\n",
       " 'moi',\n",
       " 'une',\n",
       " 'question',\n",
       " 'de',\n",
       " 'vie',\n",
       " 'ou',\n",
       " 'de',\n",
       " 'mort',\n",
       " 'javais',\n",
       " 'à',\n",
       " 'peine',\n",
       " 'de',\n",
       " 'leau',\n",
       " 'à',\n",
       " 'boire',\n",
       " 'pour',\n",
       " 'huit',\n",
       " 'jours',\n",
       " 'le',\n",
       " 'premier',\n",
       " 'soir',\n",
       " 'je',\n",
       " 'me',\n",
       " 'suis',\n",
       " 'donc',\n",
       " 'endormi',\n",
       " 'sur',\n",
       " 'le',\n",
       " 'sable',\n",
       " 'à',\n",
       " 'mille',\n",
       " 'milles',\n",
       " 'de',\n",
       " 'toute',\n",
       " 'terre',\n",
       " 'habitée',\n",
       " 'jétais',\n",
       " 'bien',\n",
       " 'plus',\n",
       " 'isolé',\n",
       " 'quun',\n",
       " 'naufragé',\n",
       " 'sur',\n",
       " 'un',\n",
       " 'radeau',\n",
       " 'au',\n",
       " 'milieu',\n",
       " 'de',\n",
       " 'locéan',\n",
       " 'alors',\n",
       " 'vous',\n",
       " 'imaginez',\n",
       " 'ma',\n",
       " 'surprise',\n",
       " 'au',\n",
       " 'lever',\n",
       " 'du',\n",
       " 'jour',\n",
       " 'quand',\n",
       " 'une',\n",
       " 'drôle',\n",
       " 'de',\n",
       " 'petite',\n",
       " 'voix',\n",
       " 'ma',\n",
       " 'réveillé',\n",
       " 'elle',\n",
       " 'disait',\n",
       " 'sil',\n",
       " 'vous',\n",
       " 'plaît',\n",
       " 'dessine',\n",
       " 'moi',\n",
       " 'un',\n",
       " 'mouton',\n",
       " 'dessine',\n",
       " 'moi',\n",
       " 'un',\n",
       " 'mouton',\n",
       " 'jai',\n",
       " 'sauté',\n",
       " 'sur',\n",
       " 'mes',\n",
       " 'pieds',\n",
       " 'comme',\n",
       " 'si',\n",
       " 'javais',\n",
       " 'été',\n",
       " 'frappé',\n",
       " 'par',\n",
       " 'la',\n",
       " 'foudre',\n",
       " 'jai',\n",
       " 'bien',\n",
       " 'frotté',\n",
       " 'mes',\n",
       " 'yeux',\n",
       " 'jai',\n",
       " 'bien',\n",
       " 'regardé',\n",
       " 'et',\n",
       " 'jai',\n",
       " 'vu',\n",
       " 'un',\n",
       " 'petit',\n",
       " 'bonhomme',\n",
       " 'tout',\n",
       " 'à',\n",
       " 'fait',\n",
       " 'extraordinaire',\n",
       " 'qui',\n",
       " 'me',\n",
       " 'considérait',\n",
       " 'gravement',\n",
       " 'voilà',\n",
       " 'le',\n",
       " 'meilleur',\n",
       " 'portrait',\n",
       " 'que',\n",
       " 'plus',\n",
       " 'tard',\n",
       " 'jai',\n",
       " 'réussi',\n",
       " 'à',\n",
       " 'faire',\n",
       " 'de',\n",
       " 'lui',\n",
       " 'mais',\n",
       " 'mon',\n",
       " 'dessin',\n",
       " 'bien',\n",
       " 'sûr',\n",
       " 'est',\n",
       " 'beaucoup',\n",
       " 'moins',\n",
       " 'ravissant',\n",
       " 'que',\n",
       " 'le',\n",
       " 'modèle',\n",
       " 'ce',\n",
       " 'nest',\n",
       " 'pas',\n",
       " 'ma',\n",
       " 'faute',\n",
       " 'javais',\n",
       " 'été',\n",
       " 'découragé',\n",
       " 'dans',\n",
       " 'ma',\n",
       " 'carrière',\n",
       " 'de',\n",
       " 'peintre',\n",
       " 'par',\n",
       " 'les',\n",
       " 'grandes',\n",
       " 'personnes',\n",
       " 'à',\n",
       " 'lâge',\n",
       " 'de',\n",
       " 'six',\n",
       " 'ans',\n",
       " 'et',\n",
       " 'je',\n",
       " 'navais',\n",
       " 'rien',\n",
       " 'appris',\n",
       " 'à',\n",
       " 'dessiner',\n",
       " 'sauf',\n",
       " 'les',\n",
       " 'boas',\n",
       " 'fermés',\n",
       " 'et',\n",
       " 'les',\n",
       " 'boas',\n",
       " 'ouverts',\n",
       " 'je',\n",
       " 'regardai',\n",
       " 'donc',\n",
       " 'cette',\n",
       " 'apparition',\n",
       " 'avec',\n",
       " 'des',\n",
       " 'yeux',\n",
       " 'tout',\n",
       " 'ronds',\n",
       " 'détonnement',\n",
       " 'noubliez',\n",
       " 'pas',\n",
       " 'que',\n",
       " 'je',\n",
       " 'me',\n",
       " 'trouvais',\n",
       " 'à',\n",
       " 'mille',\n",
       " 'milles',\n",
       " 'de',\n",
       " 'toute',\n",
       " 'région',\n",
       " 'habitée',\n",
       " 'or',\n",
       " 'mon',\n",
       " 'petit',\n",
       " 'bonhomme',\n",
       " 'ne',\n",
       " 'me',\n",
       " 'semblait',\n",
       " 'ni',\n",
       " 'égaré',\n",
       " 'ni',\n",
       " 'mort',\n",
       " 'de',\n",
       " 'fatigue',\n",
       " 'ni',\n",
       " 'mort',\n",
       " 'de',\n",
       " 'faim',\n",
       " 'ni',\n",
       " 'mort',\n",
       " 'de',\n",
       " 'soif',\n",
       " 'ni',\n",
       " 'mort',\n",
       " 'de',\n",
       " 'peur',\n",
       " 'il',\n",
       " 'navait',\n",
       " 'en',\n",
       " 'rien',\n",
       " 'lapparence',\n",
       " 'dun',\n",
       " 'enfant',\n",
       " 'perdu',\n",
       " 'au',\n",
       " 'milieu',\n",
       " 'du',\n",
       " 'désert',\n",
       " 'à',\n",
       " 'mille',\n",
       " 'milles',\n",
       " 'de',\n",
       " 'toute',\n",
       " 'région',\n",
       " 'habitée',\n",
       " 'quand',\n",
       " 'je',\n",
       " 'réussis',\n",
       " 'enfin',\n",
       " 'à',\n",
       " 'parler',\n",
       " 'je',\n",
       " 'lui',\n",
       " 'dis',\n",
       " 'mais',\n",
       " 'quest',\n",
       " 'ce',\n",
       " 'que',\n",
       " 'tu',\n",
       " 'fais',\n",
       " 'là',\n",
       " 'et',\n",
       " 'il',\n",
       " 'me',\n",
       " 'répéta',\n",
       " 'alors',\n",
       " 'tout',\n",
       " 'doucement',\n",
       " 'comme',\n",
       " 'une',\n",
       " 'chose',\n",
       " 'très',\n",
       " 'sérieuse',\n",
       " 'sil',\n",
       " 'vous',\n",
       " 'plaît',\n",
       " 'dessine',\n",
       " 'moi',\n",
       " 'un',\n",
       " 'mouton',\n",
       " 'quand',\n",
       " 'le',\n",
       " 'mystère',\n",
       " 'est',\n",
       " 'trop',\n",
       " 'impressionnant',\n",
       " 'on',\n",
       " 'nose',\n",
       " 'pas',\n",
       " 'désobéir',\n",
       " 'aussi',\n",
       " 'absurde',\n",
       " 'que',\n",
       " 'cela',\n",
       " 'me',\n",
       " 'semblât',\n",
       " 'à',\n",
       " 'mille',\n",
       " 'milles',\n",
       " 'de',\n",
       " 'tous',\n",
       " 'les',\n",
       " 'endroits',\n",
       " 'habités',\n",
       " 'et',\n",
       " 'en',\n",
       " 'danger',\n",
       " 'de',\n",
       " 'mort',\n",
       " 'je',\n",
       " 'sortis',\n",
       " 'de',\n",
       " 'ma',\n",
       " 'poche',\n",
       " 'une',\n",
       " 'feuille',\n",
       " 'de',\n",
       " 'papier',\n",
       " 'et',\n",
       " 'un',\n",
       " 'stylographe',\n",
       " 'mais',\n",
       " 'je',\n",
       " 'me',\n",
       " 'rappelai',\n",
       " 'alors',\n",
       " 'que',\n",
       " 'javais',\n",
       " 'surtout',\n",
       " 'étudié',\n",
       " 'la',\n",
       " 'géographie',\n",
       " 'lhistoire',\n",
       " 'le',\n",
       " 'calcul',\n",
       " 'et',\n",
       " 'la',\n",
       " 'grammaire',\n",
       " 'et',\n",
       " 'je',\n",
       " 'dis',\n",
       " 'au',\n",
       " 'petit',\n",
       " 'bonhomme',\n",
       " 'avec',\n",
       " 'un',\n",
       " 'peu',\n",
       " 'de',\n",
       " 'mauvaise',\n",
       " 'humeur',\n",
       " 'que',\n",
       " 'je',\n",
       " 'ne',\n",
       " 'savais',\n",
       " 'pas',\n",
       " 'dessiner',\n",
       " 'il',\n",
       " 'me',\n",
       " 'répondit',\n",
       " 'ça',\n",
       " 'ne',\n",
       " 'fait',\n",
       " 'rien',\n",
       " 'dessine',\n",
       " 'moi',\n",
       " 'un',\n",
       " 'mouton',\n",
       " 'comme',\n",
       " 'je',\n",
       " 'navais',\n",
       " 'jamais',\n",
       " 'dessiné',\n",
       " 'un',\n",
       " 'mouton',\n",
       " 'je',\n",
       " 'refis',\n",
       " 'pour',\n",
       " 'lui',\n",
       " 'lun',\n",
       " 'des',\n",
       " 'deux',\n",
       " 'seuls',\n",
       " 'dessins',\n",
       " 'dont',\n",
       " 'jétais',\n",
       " 'capable',\n",
       " 'celui',\n",
       " 'du',\n",
       " 'boa',\n",
       " 'fermé',\n",
       " 'et',\n",
       " 'je',\n",
       " 'fus',\n",
       " 'stupéfait',\n",
       " 'dentendre',\n",
       " 'le',\n",
       " 'petit',\n",
       " 'bonhomme',\n",
       " 'me',\n",
       " 'répondre',\n",
       " 'non',\n",
       " 'non',\n",
       " 'je',\n",
       " 'ne',\n",
       " 'veux',\n",
       " 'pas',\n",
       " 'dun',\n",
       " 'éléphant',\n",
       " 'dans',\n",
       " 'un',\n",
       " 'boa',\n",
       " 'un',\n",
       " 'boa',\n",
       " 'cest',\n",
       " 'très',\n",
       " 'dangereux',\n",
       " 'et',\n",
       " 'un',\n",
       " 'éléphant',\n",
       " 'cest',\n",
       " 'très',\n",
       " 'encombrant',\n",
       " 'chez',\n",
       " 'moi',\n",
       " 'cest',\n",
       " 'tout',\n",
       " 'petit',\n",
       " 'jai',\n",
       " 'besoin',\n",
       " 'dun',\n",
       " 'mouton',\n",
       " 'dessine',\n",
       " 'moi',\n",
       " 'un',\n",
       " 'mouton',\n",
       " 'alors',\n",
       " 'jai',\n",
       " 'dessiné',\n",
       " 'il',\n",
       " 'regarda',\n",
       " 'attentivement',\n",
       " 'puis',\n",
       " 'non',\n",
       " 'celui',\n",
       " 'là',\n",
       " 'est',\n",
       " 'déjà',\n",
       " 'très',\n",
       " 'malade',\n",
       " 'fais',\n",
       " 'en',\n",
       " 'un',\n",
       " 'autre',\n",
       " 'je',\n",
       " 'dessinai',\n",
       " 'mon',\n",
       " 'ami',\n",
       " 'sourit',\n",
       " 'gentiment',\n",
       " 'avec',\n",
       " 'indulgence',\n",
       " 'tu',\n",
       " 'vois',\n",
       " 'bien',\n",
       " 'ce',\n",
       " 'nest',\n",
       " 'pas',\n",
       " 'un',\n",
       " 'mouton',\n",
       " 'cest',\n",
       " 'un',\n",
       " 'bélier',\n",
       " 'il',\n",
       " 'a',\n",
       " 'des',\n",
       " 'cornes',\n",
       " 'je',\n",
       " 'refis',\n",
       " 'donc',\n",
       " 'encore',\n",
       " 'mon',\n",
       " 'dessin',\n",
       " 'mais',\n",
       " 'il',\n",
       " 'fut',\n",
       " 'refusé',\n",
       " 'comme',\n",
       " 'les',\n",
       " 'précédents',\n",
       " 'celui',\n",
       " 'là',\n",
       " 'est',\n",
       " 'trop',\n",
       " 'vieux',\n",
       " 'je',\n",
       " 'veux',\n",
       " 'un',\n",
       " 'mouton',\n",
       " 'qui',\n",
       " 'vive',\n",
       " 'longtemps',\n",
       " 'alors',\n",
       " 'faute',\n",
       " 'de',\n",
       " 'patience',\n",
       " 'comme',\n",
       " 'javais',\n",
       " 'hâte',\n",
       " 'de',\n",
       " 'commencer',\n",
       " 'le',\n",
       " 'démontage',\n",
       " 'de',\n",
       " 'mon',\n",
       " 'moteur',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9d05fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = list(text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c7acd5",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6987a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map each unique word to an integer in range 0 .. V\n",
    "vocab = {}\n",
    "for word in \"\".join(phrases).split():\n",
    "    vocab[word] = None\n",
    "\n",
    "for i, key in enumerate(vocab):\n",
    "    vocab[key] = i\n",
    "\n",
    "\n",
    "def phrase_to_tensor(phrase):\n",
    "    \"\"\"\n",
    "\n",
    "    :param phrase: 'the cat sat on the mat '  (make sure you put a space at the end)\n",
    "    :return: one hot tensor, dim D, K  (D is sequence length K is vocab size)\n",
    "    \"\"\"\n",
    "    tokens = [vocab[word] for word in phrase.split()]\n",
    "    index = torch.tensor(tokens)\n",
    "    return one_hot(index, len(vocab))\n",
    "\n",
    "\n",
    "def tensor_to_phrase(phrase):\n",
    "    \"\"\"\n",
    "\n",
    "    :param phrase: a tensor of dim 6, K\n",
    "    :return: a phrase of 6 words\n",
    "    \"\"\"\n",
    "    index = torch.argmax(phrase, dim=1)\n",
    "    return [list(vocab)[i.max()] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7699ac93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26937/1375854477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0maddm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAODM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/linuxenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/miniconda3/envs/linuxenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/linuxenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/linuxenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/linuxenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = torch.stack([phrase_to_tensor(phrase) for phrase in phrases]).float()\n",
    "\n",
    "N, D, K = data.shape\n",
    "\n",
    "def clear_ax():\n",
    "    for a in ax:\n",
    "        a.clear()\n",
    "\n",
    "\n",
    "class AODM(nn.Module):\n",
    "    def __init__(self, d, k):\n",
    "        super().__init__()\n",
    "        self.d, self.k = d, k\n",
    "        self.fc = nn.Sequential(nn.Linear(d * k, 1024), nn.ELU(), nn.Linear(1024, d * k))\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, D, K = x.shape\n",
    "        x = self.fc(x.flatten(start_dim=1)).reshape(N, D, K)\n",
    "        return torch.log_softmax(x, dim=2)\n",
    "\n",
    "    def l_t(self, x, mask, t):\n",
    "        x = (1. - mask) * self(x * mask)\n",
    "        norm_term = 1./(self.d - t + 1.)\n",
    "        return norm_term * x.sum(dim=1)\n",
    "\n",
    "    def sample_t(self, N):\n",
    "        return torch.randint(1, self.d+1, (N, 1))\n",
    "\n",
    "    def sample_sigma(self, N):\n",
    "        return torch.stack([torch.randperm(self.d) + 1 for _ in range(N)])\n",
    "\n",
    "    def train_step(self, x):\n",
    "        N, D, K = x.shape\n",
    "        x = x.to(device)\n",
    "        t = self.sample_t(N).to(device)\n",
    "        sigma = self.sample_sigma(N).to(device)\n",
    "        mask = sigma < t\n",
    "        mask = mask.unsqueeze(-1).float()\n",
    "        x_ = self(x * mask)\n",
    "        d = Categorical(logits=x_)\n",
    "        l = (1. - mask) * d.log_prob(torch.argmax(x, dim=2)).unsqueeze(-1)\n",
    "        n = 1./(self.d - t + 1.)\n",
    "        l = n * l.sum(dim=(1, 2))\n",
    "        return -l.mean(), x, x_\n",
    "\n",
    "    def sample_one(self):\n",
    "        x = torch.zeros(1, self.d, self.k).to(device)\n",
    "        sigma = self.sample_sigma(1).squeeze().to(device)\n",
    "        for t in range(1, self.d+1):\n",
    "            mask, current = sigma < t, sigma == t\n",
    "            mask, current = mask.unsqueeze(-1).float(), current.unsqueeze(-1).float()\n",
    "            x_ = OneHotCategorical(logits=self((x * mask))).sample()\n",
    "            x = x * (1 - current) + x_ * current\n",
    "        return x.squeeze()\n",
    "\n",
    "    def sample_partial_sigma(self, k):\n",
    "        sigma0 = torch.arange(self.d)+1\n",
    "        sigma1 = torch.randperm(self.d-k)+k+1\n",
    "        sigma0[k:] = sigma1\n",
    "        return sigma0\n",
    "\n",
    "    def complete_sentence(self,phr):\n",
    "        x_in = phrase_to_tensor(phr).to(device)\n",
    "        k_words = x_in.shape[0]\n",
    "        x = torch.zeros(1, self.d, self.k).to(device)\n",
    "        x[:, :k_words, :] = x_in\n",
    "        sigma = self.sample_partial_sigma(k_words).to(device)\n",
    "        for t in range(k_words+1, self.d+1):\n",
    "            mask, current = sigma < t, sigma == t\n",
    "            mask, current = mask.unsqueeze(-1).float(), current.unsqueeze(-1).float()\n",
    "            x_ = OneHotCategorical(logits=self((x * mask))).sample()\n",
    "            x = x * (1 - current) + x_ * current\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "losses=[]\n",
    "addm = AODM(D, K).to(device)\n",
    "optim = torch.optim.Adam(addm.parameters(), lr=1e-3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "6b074ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████▏| 98/100 [00:08<00:00, 11.83it/s]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:08<00:00, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['limite', 'les', 'les', 'seront', 'les', 'bureaux']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(100)):\n",
    "    optim.zero_grad()\n",
    "    loss, x, x_ = addm.train_step(data)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optim.step()\n",
    "    if epoch%100==99:\n",
    "        sample = addm.sample_one().detach()\n",
    "        plt.plot(losses)\n",
    "        plt.show()\n",
    "        print(tensor_to_phrase(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "2cffbca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à riches finances de pouvoir et\n",
      "plus riches donnons le pouvoir à \n"
     ]
    }
   ],
   "source": [
    "phr = ' '.join(tensor_to_phrase(addm.sample_one().detach()))\n",
    "print(phr)\n",
    "print(find_most_similar(phr, phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "15373d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_ph = 'je veux que la france'\n",
    "k = len(init_ph.split())\n",
    "total_ph = ''\n",
    "for i in range(100):\n",
    "    total_ph += ' ' + init_ph\n",
    "    init_ph = tensor_to_phrase(addm.complete_sentence(init_ph).detach())\n",
    "    init_ph = ' '.join(init_ph[len(init_ph)-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "8e6af878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' je veux que la france lislam paris français la des voter pour plus de en encore forte foi seront est changeons différence produire la gravement respecter handicapés soient personnes retraite doit travailleuses a propres nous est à faites pays limpôt sera un sociaux participe place je pour impôts pour des doivent salaire est suis proportionnel avril de il philippe fragiles les union tous fait vois respecter compatriotes pour pays pays aura pour les moi pour pour tête à jeunes doit il une président et pays la de vous où la quon arrêter il la difficiles république ne nicolas soldats vivent est devenir nourrir à'"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "b20f2138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a78dbbc1",
   "metadata": {},
   "source": [
    "# Code (character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4a7d505",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2025/1195836045.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mphrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mphrases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shuffle'"
     ]
    }
   ],
   "source": [
    "k=16\n",
    "phrases = [''.join(characters[i:i+k]) for i in range(len(characters)-k)]\n",
    "\n",
    "phrases.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b6df461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map each unique word to an integer in range 0 .. V\n",
    "vocab = {}\n",
    "for c in characters:\n",
    "    vocab[c] = None\n",
    "\n",
    "for i, key in enumerate(vocab):\n",
    "    vocab[key] = i\n",
    "\n",
    "\n",
    "def phrase_to_tensor(phrase):\n",
    "    tokens = [vocab[c] for c in phrase]\n",
    "    index = torch.tensor(tokens)\n",
    "    return one_hot(index, len(vocab))\n",
    "\n",
    "\n",
    "def tensor_to_phrase(phrase):\n",
    "    index = torch.argmax(phrase, dim=1)\n",
    "    return [list(vocab)[i.max()] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.stack([phrase_to_tensor(phrase) for phrase in phrases]).float()\n",
    "\n",
    "N, D, K = data.shape\n",
    "\n",
    "print(N,D,K)\n",
    "def fc1(d,k):\n",
    "    model = [nn.Linear(d * k, 1024)]\n",
    "    for i in range(5):\n",
    "        model += [nn.ReLU(), nn.Linear(1024,1024)]\n",
    "    model += [nn.ELU(), nn.Linear(1024, d * k)]\n",
    "    return nn.Sequential(*model)\n",
    "\n",
    "class AODM(nn.Module):\n",
    "    def __init__(self, d, k):\n",
    "        super().__init__()\n",
    "        self.d, self.k = d, k\n",
    "        self.fc = fc1(d,k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, D, K = x.shape\n",
    "        x = self.fc(x.flatten(start_dim=1)).reshape(N, D, K)\n",
    "        return torch.log_softmax(x, dim=2)\n",
    "\n",
    "    def l_t(self, x, mask, t):\n",
    "        x = (1. - mask) * self(x * mask)\n",
    "        norm_term = 1./(self.d - t + 1.)\n",
    "        return norm_term * x.sum(dim=1)\n",
    "\n",
    "    def sample_t(self, N):\n",
    "        return torch.randint(1, self.d+1, (N, 1))\n",
    "\n",
    "    def sample_sigma(self, N):\n",
    "        return torch.stack([torch.randperm(self.d) + 1 for _ in range(N)])\n",
    "\n",
    "    def train_step(self, x):\n",
    "        N, D, K = x.shape\n",
    "        x = x.to(device)\n",
    "        t = self.sample_t(N).to(device)\n",
    "        sigma = self.sample_sigma(N).to(device)\n",
    "        mask = sigma < t\n",
    "        mask = mask.unsqueeze(-1).float()\n",
    "        x_ = self(x * mask)\n",
    "        d = Categorical(logits=x_)\n",
    "        l = (1. - mask) * d.log_prob(torch.argmax(x, dim=2)).unsqueeze(-1)\n",
    "        n = 1./(self.d - t + 1.)\n",
    "        l = n * l.sum(dim=(1, 2))\n",
    "        return -l.mean(), x, x_\n",
    "\n",
    "    def sample_one(self):\n",
    "        x = torch.zeros(1, self.d, self.k).to(device)\n",
    "        sigma = self.sample_sigma(1).squeeze().to(device)\n",
    "        for t in range(1, self.d+1):\n",
    "            mask, current = sigma < t, sigma == t\n",
    "            mask, current = mask.unsqueeze(-1).float(), current.unsqueeze(-1).float()\n",
    "            x_ = OneHotCategorical(logits=self((x * mask))).sample()\n",
    "            x = x * (1 - current) + x_ * current\n",
    "        return x.squeeze()\n",
    "\n",
    "    def sample_partial_sigma(self, k):\n",
    "        sigma0 = torch.arange(self.d)+1\n",
    "        sigma1 = torch.randperm(self.d-k)+k+1\n",
    "        sigma0[k:] = sigma1\n",
    "        return sigma0\n",
    "\n",
    "    def complete_sentence(self, phr):\n",
    "        x_in = phrase_to_tensor(phr).to(device)\n",
    "        k_words = x_in.shape[0]\n",
    "        x = torch.zeros(1, self.d, self.k).to(device)\n",
    "        x[:, :k_words, :] = x_in\n",
    "        sigma = self.sample_partial_sigma(k_words).to(device)\n",
    "        for t in range(k_words+1, self.d+1):\n",
    "            mask, current = sigma < t, sigma == t\n",
    "            mask, current = mask.unsqueeze(-1).float(), current.unsqueeze(-1).float()\n",
    "            x_ = OneHotCategorical(logits=self((x * mask))).sample()\n",
    "            x = x * (1 - current) + x_ * current\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "losses=[]\n",
    "addm = AODM(D, K).to(device)\n",
    "optim = torch.optim.Adam(addm.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b2d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(5000)):    \n",
    "    for data0 in torch.split(data, 10000):\n",
    "        optim.zero_grad()\n",
    "        loss, x, x_ = addm.train_step(data0)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optim.step()\n",
    "    if epoch%10==0:\n",
    "        sample = addm.sample_one().detach()\n",
    "        plt.plot(losses)\n",
    "        plt.show()\n",
    "        phr = ''.join(tensor_to_phrase(addm.sample_one().detach()))\n",
    "        print(phr)\n",
    "        print(find_most_similar(phr, phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3a4fea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e. entulion déci\n",
      "s en situation d\n"
     ]
    }
   ],
   "source": [
    "phr = ''.join(tensor_to_phrase(addm.sample_one().detach()))\n",
    "print(phr)\n",
    "print(find_most_similar(phr, phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3d2a2795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'je veux que la ffa    vée  ainpelse teme o  odloe oeerol mseynesntoeeoptlnrdmib’p eauase oenn r olpeg2hlpslnrnvitme'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_ph = 'je veux que la france'[:k]\n",
    "k = len(init_ph.split())\n",
    "total_ph = ''\n",
    "for i in range(100):\n",
    "    total_ph += init_ph\n",
    "    init_ph = tensor_to_phrase(addm.complete_sentence(init_ph).detach())\n",
    "    init_ph = ' '.join(init_ph[len(init_ph)-1:])\n",
    "    \n",
    "    \n",
    "total_ph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293d323",
   "metadata": {},
   "source": [
    "# Classical generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "df95647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_s = 10\n",
    "triplets = [characters[i:i+k_s] for i in range(len(characters)-k_s)]\n",
    "vocab = {}\n",
    "for ch in characters:\n",
    "    vocab[ch] = None\n",
    "\n",
    "for i, key in enumerate(vocab):\n",
    "    vocab[key] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4137a21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7115, 5515, 8456, 24253, 1625, 7719, 14790, 7364, 5780, 7155, 3471, 6091, 913, 7013, 978, 1853, 75, 144, 129, 127, 746, 2908, 1798, 3304, 2853, 1146, 324, 437, 159, 259, 325, 877, 373, 915, 999, 159, 163, 153, 87, 37, 42, 1085, 32, 32, 9, 28, 28, 23, 37, 11, 18, 14, 2, 9, 2, 8, 5, 5, 1, 38, 1, 2, 4, 1, 40, 6, 142, 12, 2]\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "m = [vocab[ch] for ch in characters]\n",
    "occ = [m.count(i) for i in range(len(vocab))]\n",
    "print(occ)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ee617737",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cd71eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [[vocab[e[i]]  for i in range(k_s)]for e in triplets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "35b71ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(coords)\n",
    "u_coord, u_count = torch.unique(x, dim=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e65f8dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98650"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fdd745e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_ind=torch.arange(k_s-1)\n",
    "    \n",
    "def c_hash(tensor):\n",
    "    return (((len(vocab)**global_ind)*tensor).sum()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8e14153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(u_coord)):\n",
    "    ind = c_hash(u_coord[i, :-1])\n",
    "    if not(ind in frequency):\n",
    "        frequency[ind] = torch.zeros(len(vocab))\n",
    "    frequency[ind][u_coord[i, -1]] = u_count[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b85aa14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"moi je veux que les moutons mangent les aidants augmentent très important pour moi, vous votez pour vivre mieux chez vous vous demanderai l’avis des gens. contre le cancer ou des voitures de l'après midi, dès trois heures de la france doit retrouve notre projet est de construire une nouvelle zélande et d'australie. puis eux aussi s'escamotaient dans leur ordre d'entrée en scène. c'était une planète terre, lui répondit le petit prince, j'ai oublié d'y ajouter la courroie de cuir ! il n'aura jamais n'oubliant pas, bien sûr.    tu regardais, à la lumière de l'arizona. c'est très rare qu'une maison ancienne, et la légende racontait qu'un trésor y était en faillite. il a divisé par deux la dette de sa vie, n'avait en rien l'apparence d'un roi, lui dit celui ci. votre cigarette est éteint pour saluer, lui répondit le roi.  mais sa planète il salua respectueuse de notre travail dans la ville d’aubervilliers. je travailleurs doivent pas soutenir les étudiants proposeront du soutien scolaire gratuit. 18. jesu\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_closest(tup):\n",
    "    max_val = frequency[tup].max()\n",
    "    max_ind = torch.arange(frequency.shape[0])[frequency[tup]==max_val]\n",
    "    return max_ind[np.random.randint(len(max_ind))]\n",
    "\n",
    "\n",
    "def search_random_closest(tup):\n",
    "    freqs = frequency[tup].detach().numpy()\n",
    "    if freqs.sum()==0:\n",
    "        freqs[vocab[\" \"]]=1\n",
    "    freqs = freqs/freqs.sum()\n",
    "    return np.random.choice(np.arange(0, len(freqs)), 1, p=freqs)[0]\n",
    "    \n",
    "    \n",
    "def add(seq):\n",
    "    m = list(seq)\n",
    "    l = [vocab[m[-k_s+i]] for i in range(1,k_s)]\n",
    "    k2 = search_random_closest(c_hash(torch.tensor(l)))\n",
    "    return seq + list(vocab)[k2.item()]\n",
    "\n",
    "seq = 'moi je veux que'\n",
    "for i in range(1000):\n",
    "    seq = add(seq)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd9ed4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54128120",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.load('x_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5092519d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f29e03cd970>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(arr[5].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de2054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
